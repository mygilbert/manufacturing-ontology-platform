{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDC 이상감지 알고리즘 추천 Agent\n",
    "\n",
    "FDC(Fault Detection and Classification)에서 1초 단위로 수집되는 PV(Process Variable) 데이터를 분석하여 최적의 이상감지 알고리즘을 자동으로 추천합니다.\n",
    "\n",
    "## 주요 기능\n",
    "1. **데이터 로딩 및 전처리**: CSV 형태의 PV 데이터와 이상 발생 시점 정보 로딩\n",
    "2. **탐색적 데이터 분석 (EDA)**: 데이터 특성 자동 분석\n",
    "3. **특성 공학**: 이상감지에 유용한 특성 자동 추출\n",
    "4. **알고리즘 학습 및 평가**: 8가지 이상감지 알고리즘 비교\n",
    "5. **최적 알고리즘 추천**: 데이터 특성 기반 자동 추천\n",
    "6. **결과 리포트 생성**: 상세 분석 리포트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 경로 설정\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 시각화 설정\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# 커스텀 모듈\n",
    "from anomaly_detection import DataLoader, FeatureEngineer, ModelEvaluator, AlgorithmRecommender\n",
    "from anomaly_detection.algorithms import (\n",
    "    ZScoreDetector, CUSUMDetector, SPCDetector,\n",
    "    IsolationForestDetector, LOFDetector, OneClassSVMDetector,\n",
    "    AutoEncoderDetector, LSTMAutoEncoderDetector\n",
    ")\n",
    "\n",
    "print(\"환경 설정 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 로딩\n",
    "\n",
    "PV 데이터와 이상 발생 시점 정보를 로딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정 (샘플 데이터 또는 실제 데이터 경로로 변경)\n",
    "PV_DATA_PATH = '../sample_data/sample_pv_data.csv'\n",
    "FAULT_LABELS_PATH = '../sample_data/sample_fault_labels.csv'\n",
    "\n",
    "# 샘플 데이터가 없으면 생성\n",
    "if not os.path.exists(PV_DATA_PATH):\n",
    "    print(\"샘플 데이터가 없습니다. 생성 중...\")\n",
    "    exec(open('../scripts/generate_sample_data.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 초기화\n",
    "loader = DataLoader()\n",
    "\n",
    "# PV 데이터 로딩\n",
    "pv_data = loader.load_pv_data(PV_DATA_PATH)\n",
    "print(f\"\\nPV 데이터 컬럼: {list(pv_data.columns)}\")\n",
    "pv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상 발생 정보 로딩\n",
    "fault_labels = loader.load_fault_labels(FAULT_LABELS_PATH)\n",
    "print(f\"\\n이상 발생 정보:\")\n",
    "fault_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 병합\n",
    "merged_data = loader.merge_data()\n",
    "\n",
    "# 전처리\n",
    "processed_data = loader.preprocess(fill_missing='interpolate')\n",
    "print(f\"\\n전처리 완료 데이터 shape: {processed_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 탐색적 데이터 분석 (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 특성 분석\n",
    "characteristics = loader.analyze_characteristics()\n",
    "\n",
    "# 요약 정보 출력\n",
    "summary = loader.summary()\n",
    "print(\"=\" * 50)\n",
    "print(\"데이터 특성 요약\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 시각화\n",
    "feature_cols = loader.get_feature_columns()\n",
    "\n",
    "fig, axes = plt.subplots(len(feature_cols), 1, figsize=(14, 3*len(feature_cols)), sharex=True)\n",
    "\n",
    "for i, col in enumerate(feature_cols):\n",
    "    ax = axes[i] if len(feature_cols) > 1 else axes\n",
    "    \n",
    "    # 정상 데이터\n",
    "    normal_mask = processed_data['is_anomaly'] == 0\n",
    "    ax.plot(processed_data.loc[normal_mask, 'timestamp'], \n",
    "            processed_data.loc[normal_mask, col], \n",
    "            'b-', alpha=0.5, label='정상', linewidth=0.5)\n",
    "    \n",
    "    # 이상 데이터\n",
    "    anomaly_mask = processed_data['is_anomaly'] == 1\n",
    "    ax.scatter(processed_data.loc[anomaly_mask, 'timestamp'], \n",
    "               processed_data.loc[anomaly_mask, col], \n",
    "               c='red', s=1, alpha=0.5, label='이상')\n",
    "    \n",
    "    ax.set_ylabel(col)\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "axes[-1].set_xlabel('Timestamp') if len(feature_cols) > 1 else axes.set_xlabel('Timestamp')\n",
    "plt.suptitle('PV 데이터 시계열 (빨간점: 이상)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관관계 히트맵\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = processed_data[feature_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('센서 간 상관관계')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상 유형별 분포 (fault_labels에서)\n",
    "if 'fault_type' in fault_labels.columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    fault_labels['fault_type'].value_counts().plot(kind='bar', color='coral')\n",
    "    plt.title('이상 유형별 발생 빈도')\n",
    "    plt.xlabel('이상 유형')\n",
    "    plt.ylabel('발생 횟수')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 특성 공학 (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 추출기 초기화\n",
    "feature_engineer = FeatureEngineer()\n",
    "\n",
    "# 특성 추출 (시간이 걸릴 수 있음)\n",
    "print(\"특성 추출 중... (데이터 크기에 따라 몇 분 소요될 수 있습니다)\")\n",
    "enriched_data = feature_engineer.extract_all_features(\n",
    "    data=processed_data,\n",
    "    feature_cols=feature_cols,\n",
    "    window_sizes=[5, 10, 30],\n",
    "    include_fft=True,\n",
    "    include_peaks=True\n",
    ")\n",
    "\n",
    "print(f\"\\n추출된 특성 수: {len(feature_engineer.feature_names)}\")\n",
    "print(f\"최종 데이터 shape: {enriched_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 중요도 분석\n",
    "importance_df = feature_engineer.get_feature_importance_ranking(enriched_data)\n",
    "\n",
    "# 상위 20개 특성 시각화\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_n = 20\n",
    "plt.barh(range(top_n), importance_df.head(top_n)['importance'].values, color='steelblue')\n",
    "plt.yticks(range(top_n), importance_df.head(top_n)['feature'].values)\n",
    "plt.xlabel('중요도 (상관계수)')\n",
    "plt.title(f'이상 감지를 위한 상위 {top_n}개 특성')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 50개 특성 선택\n",
    "selected_data = feature_engineer.select_top_features(\n",
    "    enriched_data, \n",
    "    top_n=50, \n",
    "    keep_original=True\n",
    ")\n",
    "\n",
    "print(f\"선택된 특성 수: {selected_data.shape[1] - 2}개\")  # timestamp, is_anomaly 제외"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터 분할 및 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/테스트 분할 (시계열 순서 유지)\n",
    "train_data, test_data = loader.get_train_test_split(\n",
    "    selected_data, \n",
    "    test_ratio=0.2, \n",
    "    temporal_split=True\n",
    ")\n",
    "\n",
    "# 특성과 라벨 분리\n",
    "exclude_cols = ['timestamp', 'is_anomaly']\n",
    "feature_columns = [c for c in selected_data.columns if c not in exclude_cols]\n",
    "\n",
    "X_train = train_data[feature_columns].values\n",
    "y_train = train_data['is_anomaly'].values\n",
    "X_test = test_data[feature_columns].values\n",
    "y_test = test_data['is_anomaly'].values\n",
    "\n",
    "print(f\"학습 데이터: {X_train.shape}, 이상 비율: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"테스트 데이터: {X_test.shape}, 이상 비율: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 알고리즘 추천 및 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추천 엔진 초기화\n",
    "recommender = AlgorithmRecommender()\n",
    "\n",
    "# 데이터 특성 기반 추천\n",
    "recommendations = recommender.analyze_and_recommend(\n",
    "    characteristics=characteristics,\n",
    "    priorities={\n",
    "        'speed': 0.2,\n",
    "        'accuracy': 0.4,\n",
    "        'interpretability': 0.2,\n",
    "        'early_detection': 0.2\n",
    "    }\n",
    ")\n",
    "\n",
    "# 추천 리포트 출력\n",
    "print(recommender.generate_recommendation_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 알고리즘 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가기 초기화\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "# 모든 알고리즘 정의\n",
    "algorithms = {\n",
    "    'Z-Score': ZScoreDetector(threshold=3.0),\n",
    "    'CUSUM': CUSUMDetector(threshold=5.0),\n",
    "    'SPC': SPCDetector(n_sigma=3.0),\n",
    "    'Isolation Forest': IsolationForestDetector(contamination=0.05),\n",
    "    'LOF': LOFDetector(n_neighbors=20),\n",
    "    'One-Class SVM': OneClassSVMDetector(nu=0.05),\n",
    "}\n",
    "\n",
    "# 딥러닝 모델 추가 (데이터가 충분할 경우)\n",
    "if len(X_train) >= 5000:\n",
    "    algorithms['AutoEncoder'] = AutoEncoderDetector(epochs=30, batch_size=64)\n",
    "    \n",
    "if len(X_train) >= 10000:\n",
    "    algorithms['LSTM-AE'] = LSTMAutoEncoderDetector(sequence_length=30, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 알고리즘 평가\n",
    "scores_dict = {}\n",
    "\n",
    "for name, detector in tqdm(algorithms.items(), desc=\"알고리즘 평가\"):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"평가 중: {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    try:\n",
    "        # 학습\n",
    "        start_time = time.time()\n",
    "        detector.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # 예측\n",
    "        start_time = time.time()\n",
    "        y_pred = detector.predict(X_test)\n",
    "        prediction_time = time.time() - start_time\n",
    "        \n",
    "        # 점수\n",
    "        y_score = detector.predict_score(X_test)\n",
    "        scores_dict[name] = y_score\n",
    "        \n",
    "        # 평가\n",
    "        result = evaluator.evaluate(\n",
    "            y_true=y_test,\n",
    "            y_pred=y_pred,\n",
    "            y_score=y_score,\n",
    "            algorithm_name=name,\n",
    "            training_time=training_time,\n",
    "            prediction_time=prediction_time\n",
    "        )\n",
    "        \n",
    "        print(f\"  Precision: {result.precision:.4f}\")\n",
    "        print(f\"  Recall: {result.recall:.4f}\")\n",
    "        print(f\"  F1 Score: {result.f1_score:.4f}\")\n",
    "        print(f\"  AUC-ROC: {result.auc_roc:.4f}\")\n",
    "        print(f\"  학습 시간: {training_time:.2f}초\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  오류 발생: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 비교 테이블\n",
    "comparison_df = evaluator.compare_algorithms()\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"알고리즘 성능 비교\")\n",
    "print(\"=\"*80)\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 시각화\n",
    "try:\n",
    "    evaluator.plot_comparison(figsize=(14, 6))\n",
    "except:\n",
    "    # 기본 바 차트로 대체\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    metrics = ['precision', 'recall', 'f1_score', 'auc_roc']\n",
    "    x = np.arange(len(evaluator.results))\n",
    "    width = 0.2\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        values = [getattr(r, metric) for r in evaluator.results]\n",
    "        ax.bar(x + i*width, values, width, label=metric)\n",
    "    \n",
    "    ax.set_xticks(x + width*1.5)\n",
    "    ax.set_xticklabels([r.algorithm_name for r in evaluator.results], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.set_title('알고리즘 성능 비교')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC 곡선 비교\n",
    "if len(scores_dict) > 0 and len(np.unique(y_test)) > 1:\n",
    "    evaluator.plot_roc_curves(y_test, scores_dict, figsize=(14, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 최종 추천 및 리포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최고 성능 알고리즘 선정\n",
    "best_name, best_result = evaluator.get_best_algorithm(metric='weighted')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"최종 추천 알고리즘\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n추천: {best_name}\")\n",
    "print(f\"\\n성능 지표:\")\n",
    "print(f\"  - Accuracy: {best_result.accuracy:.4f}\")\n",
    "print(f\"  - Precision: {best_result.precision:.4f}\")\n",
    "print(f\"  - Recall: {best_result.recall:.4f}\")\n",
    "print(f\"  - F1 Score: {best_result.f1_score:.4f}\")\n",
    "print(f\"  - AUC-ROC: {best_result.auc_roc:.4f}\")\n",
    "print(f\"  - AUC-PR: {best_result.auc_pr:.4f}\")\n",
    "print(f\"  - 조기 감지 점수: {best_result.early_detection_score:.4f}\")\n",
    "print(f\"\\n혼동 행렬:\")\n",
    "print(f\"  TN: {best_result.confusion_matrix[0,0]}, FP: {best_result.confusion_matrix[0,1]}\")\n",
    "print(f\"  FN: {best_result.confusion_matrix[1,0]}, TP: {best_result.confusion_matrix[1,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 평가 리포트\n",
    "print(evaluator.generate_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순위별 알고리즘 목록\n",
    "print(\"\\n알고리즘 순위 (F1 Score 기준):\")\n",
    "for i, (name, score) in enumerate(evaluator.get_ranking('f1_score'), 1):\n",
    "    print(f\"  {i}. {name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 구현 가이드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최고 성능 알고리즘의 구현 가이드\n",
    "print(recommender.get_implementation_guide(best_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "output_dir = '../results'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 비교 테이블 저장\n",
    "comparison_df.to_csv(f'{output_dir}/algorithm_comparison.csv', index=False)\n",
    "print(f\"비교 결과 저장: {output_dir}/algorithm_comparison.csv\")\n",
    "\n",
    "# 리포트 저장\n",
    "with open(f'{output_dir}/evaluation_report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(evaluator.generate_report())\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(recommender.generate_recommendation_report())\n",
    "print(f\"리포트 저장: {output_dir}/evaluation_report.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 요약\n",
    "\n",
    "이 Agent는 FDC PV 데이터를 분석하여 최적의 이상감지 알고리즘을 자동으로 추천합니다.\n",
    "\n",
    "### 사용 방법\n",
    "1. `PV_DATA_PATH`와 `FAULT_LABELS_PATH`를 실제 데이터 경로로 변경\n",
    "2. 노트북 전체 실행\n",
    "3. 추천 결과 확인 및 운영 환경 적용\n",
    "\n",
    "### 지원 알고리즘\n",
    "- **통계 기반**: Z-Score, CUSUM, SPC\n",
    "- **ML 기반**: Isolation Forest, LOF, One-Class SVM\n",
    "- **딥러닝 기반**: AutoEncoder, LSTM-AutoEncoder\n",
    "\n",
    "### 문의\n",
    "추가 기능이나 개선 사항은 개발팀에 문의하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
